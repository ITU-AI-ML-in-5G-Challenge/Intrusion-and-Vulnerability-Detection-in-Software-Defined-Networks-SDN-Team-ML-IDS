{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b335ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863d07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced95ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = train_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9df866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected features\n",
    "features = ['Total Length of Fwd Packets',\n",
    "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
    "       'Fwd Packet Length Mean', 'Bwd Packet Length Max',\n",
    "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Max',\n",
    "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
    "       'Fwd Header Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "       'Packet Length Std', 'Packet Length Variance', 'PSH Flag Count',\n",
    "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "       'Fwd Header Length.1', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
    "                   'Init_Win_bytes_forward', 'Init_Win_bytes_backward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38b63e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        1432050\n",
       "DoS Hulk                       145575\n",
       "PortScan                       100125\n",
       "DDoS                            80656\n",
       "DoS GoldenEye                    6484\n",
       "FTP-Patator                      5000\n",
       "SSH-Patator                      3714\n",
       "DoS slowloris                    3651\n",
       "DoS Slowhttptest                 3464\n",
       "Bot                              1238\n",
       "Web Attack � Brute Force          949\n",
       "Web Attack � XSS                  410\n",
       "Infiltration                       22\n",
       "Web Attack � Sql Injection         12\n",
       "Heartbleed                          6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "844444dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['Total Length of Fwd Packets',\n",
    "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
    "       'Fwd Packet Length Mean', 'Bwd Packet Length Max',\n",
    "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Max',\n",
    "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
    "       'Fwd Header Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "       'Packet Length Std', 'Packet Length Variance', 'PSH Flag Count',\n",
    "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "       'Fwd Header Length.1', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
    "                   'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'Label']\n",
    "\n",
    "# Keep only the desired columns\n",
    "df = train_df[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae2e36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1783356, 29)\n",
      "Shape of y: (1783356,)\n"
     ]
    }
   ],
   "source": [
    "y = train_df[\"Label\"]\n",
    "X = train_df[features_to_keep]\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7fbbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        1432050\n",
       "DoS Hulk                       145575\n",
       "PortScan                       100125\n",
       "DDoS                            80656\n",
       "DoS GoldenEye                    6484\n",
       "FTP-Patator                      5000\n",
       "SSH-Patator                      3714\n",
       "DoS slowloris                    3651\n",
       "DoS Slowhttptest                 3464\n",
       "Bot                              1238\n",
       "Web Attack � Brute Force          949\n",
       "Web Attack � XSS                  410\n",
       "Infiltration                       22\n",
       "Web Attack � Sql Injection         12\n",
       "Heartbleed                          6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcae7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating into different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24a7e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class labels you want to keep\n",
    "selected_classes = ['BENIGN', 'DoS Hulk', 'PortScan', 'DDoS']\n",
    "\n",
    "# Filter the original dataframe to include only the selected classes\n",
    "filtered_df = df[df['Label'].isin(selected_classes)]\n",
    "\n",
    "# Export the filtered dataframe to a CSV file\n",
    "filtered_df.to_csv('High_samples_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e0973e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class labels you want to keep\n",
    "selected_classes = ['DoS GoldenEye', 'FTP-Patator', 'SSH-Patator', 'DoS slowloris', 'DoS Slowhttptest','Bot']\n",
    "\n",
    "# Filter the original dataframe to include only the selected classes\n",
    "filtered_df2 = df[df['Label'].isin(selected_classes)]\n",
    "\n",
    "# Export the filtered dataframe to a CSV file\n",
    "filtered_df2.to_csv('Mid_samples_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7eb2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class labels you want to keep\n",
    "selected_classes = ['Web Attack � Brute Force', 'Web Attack � XSS', 'Infiltration', 'Web Attack � Sql Injection', 'Heartbleed']\n",
    "\n",
    "# Filter the original dataframe to include only the selected classes\n",
    "filtered_df3 = df[df['Label'].isin(selected_classes)]\n",
    "\n",
    "# Export the filtered dataframe to a CSV file\n",
    "filtered_df3.to_csv('Low_samples_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e755dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2d4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17a97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2813c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "384a3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Smote experiment on minority class in Low_samples file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a9ff8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data from CSV\n",
    "df = pd.read_csv('Low_samples_RF.csv')\n",
    "\n",
    "# Clean the dataset\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Drop rows with infinity or negative infinity\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "    df = df[indices_to_keep]\n",
    "\n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_dataset(df)\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "cleaned_df['Label'] = label_encoder.fit_transform(cleaned_df['Label'])\n",
    "\n",
    "oversampling_ratios = {\n",
    "    label_encoder.transform(['Web Attack � Brute Force'])[0]: 950, \n",
    "    label_encoder.transform(['Web Attack � XSS'])[0]: 800,        \n",
    "    label_encoder.transform(['Infiltration'])[0]: 250,            \n",
    "    label_encoder.transform(['Web Attack � Sql Injection'])[0]: 250, \n",
    "    label_encoder.transform(['Heartbleed'])[0]: 250\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf82a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = cleaned_df.drop(columns=['Label'])\n",
    "y = cleaned_df['Label']\n",
    "\n",
    "# Apply SMOTE to balance classes with desired ratios\n",
    "smote = SMOTE(sampling_strategy=oversampling_ratios, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create a new DataFrame for the resampled data\n",
    "resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "resampled_df['Label'] = y_resampled\n",
    "\n",
    "# Add a 'data_type' column to indicate whether the data is original or augmented\n",
    "cleaned_df['data_type'] = 'Original'\n",
    "resampled_df['data_type'] = 'Augmented'\n",
    "\n",
    "# Concatenate the original and augmented dataframes\n",
    "final_df = pd.concat([cleaned_df, resampled_df], ignore_index=True)\n",
    "\n",
    "# Decode the categorical labels back to original values\n",
    "final_df['Label'] = label_encoder.inverse_transform(final_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd1688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d9359794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Augmented instances with Label 'Heartbleed': 250\n"
     ]
    }
   ],
   "source": [
    "# Cheking number of augmented and original data per class\n",
    "augmented_heartbleed_count = final_df[(final_df['data_type'] == 'Augmented') & (final_df['Label'] == 'Heartbleed')].shape[0]\n",
    "print(\"Number of Augmented instances with Label 'Heartbleed':\", augmented_heartbleed_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "42e82263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I'll drop the augmented data from majority class to match expected number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9f8a9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(final_df[(final_df['Label'] == 'Web Attack � Brute Force') & (final_df['data_type'] == 'Augmented')].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ba71d60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Web Attack � Brute Force      949\n",
       "Web Attack � XSS              410\n",
       "Infiltration                   22\n",
       "Web Attack � Sql Injection     12\n",
       "Heartbleed                      6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "054d8acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Web Attack � XSS              1210\n",
       "Web Attack � Brute Force       949\n",
       "Infiltration                   272\n",
       "Web Attack � Sql Injection     262\n",
       "Heartbleed                     256\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5767051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Low_samples_Aug_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144af919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aba808e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with High Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12af2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1458557/2288280741.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Label'] = label_encoder.fit_transform(cleaned_df['Label'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data from CSV\n",
    "df = pd.read_csv('High_samples_RF.csv')\n",
    "\n",
    "# Clean the dataset\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Drop rows with infinity or negative infinity\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "    df = df[indices_to_keep]\n",
    "\n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_dataset(df)\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "cleaned_df['Label'] = label_encoder.fit_transform(cleaned_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc6efad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample Benign Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b22afb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa13065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = 'BENIGN'\n",
    "minority_classes = ['DoS Hulk', 'PortScan', 'DDoS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d094349",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_samples = df[df['Label'] == majority_class]\n",
    "minority_samples = df[df['Label'].isin(minority_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95c54cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "downsampled_majority = resample(majority_samples,\n",
    "                                replace=False,  # Without replacement\n",
    "                                n_samples=150000,  # Desired number of samples\n",
    "                                random_state=42)  # For reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71a89c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine minority and downsampled majority samples\n",
    "balanced_dataset = pd.concat([downsampled_majority, minority_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "379245a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to ensure randomness\n",
    "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0b3ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN      150000\n",
       "DoS Hulk    145575\n",
       "PortScan    100125\n",
       "DDoS         80656\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_dataset[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2af06016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need of augmenting the data for this class. I'll just export it in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67f4a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.to_csv('High_samples_Aug_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea9703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1de4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I'll make one final copy of all augmented data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3a86466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Low_samples_Aug_RF.csv\")\n",
    "df2 = pd.read_csv(\"Mid_samples_Aug_RF.csv\")  # in actual training, original distribution was used\n",
    "df3 = pd.read_csv(\"High_samples_Aug_RF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22e8a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Train_Aug_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b4c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d040ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
